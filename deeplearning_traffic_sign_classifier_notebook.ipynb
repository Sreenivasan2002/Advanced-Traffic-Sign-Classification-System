{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #1: UNDERSTAND THE PROBLEM STATEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Our goal is to build a multiclassifier model based on deep learning to classify various traffic signs. \n",
    "- Dataset that we are using to train the model is **German Traffic Sign Recognition Benchmark**.\n",
    "- Dataset consists of 43 classes: \n",
    "- ( 0, b'Speed limit (20km/h)') ( 1, b'Speed limit (30km/h)') ( 2, b'Speed limit (50km/h)') ( 3, b'Speed limit (60km/h)') ( 4, b'Speed limit (70km/h)') \n",
    "- ( 5, b'Speed limit (80km/h)') ( 6, b'End of speed limit (80km/h)') ( 7, b'Speed limit (100km/h)') ( 8, b'Speed limit (120km/h)') ( 9, b'No passing') \n",
    "- (10, b'No passing for vehicles over 3.5 metric tons') (11, b'Right-of-way at the next intersection') (12, b'Priority road') (13, b'Yield') (14, b'Stop') \n",
    "- (15, b'No vehicles') (16, b'Vehicles over 3.5 metric tons prohibited') (17, b'No entry')\n",
    "- (18, b'General caution') (19, b'Dangerous curve to the left')\n",
    "- (20, b'Dangerous curve to the right') (21, b'Double curve')\n",
    "- (22, b'Bumpy road') (23, b'Slippery road')\n",
    "- (24, b'Road narrows on the right') (25, b'Road work')\n",
    "- (26, b'Traffic signals') (27, b'Pedestrians') (28, b'Children crossing')\n",
    "- (29, b'Bicycles crossing') (30, b'Beware of ice/snow')\n",
    "- (31, b'Wild animals crossing')\n",
    "- (32, b'End of all speed and passing limits') (33, b'Turn right ahead')\n",
    "- (34, b'Turn left ahead') (35, b'Ahead only') (36, b'Go straight or right')\n",
    "- (37, b'Go straight or left') (38, b'Keep right') (39, b'Keep left')\n",
    "- (40, b'Roundabout mandatory') (41, b'End of no passing')\n",
    "- (42, b'End of no passing by vehicles over 3.5 metric tons')\n",
    "\n",
    "\n",
    "\n",
    "- **Data Source** - https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #2: GET THE DATA AND VISUALIZE IT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"train.p\", mode='rb') as training_data:\n",
    "    train = pickle.load(training_data)\n",
    "with open(\"valid.p\", mode='rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)\n",
    "with open(\"test.p\", mode='rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], train['labels']\n",
    "X_validation, y_validation = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12630, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "i = np.random.randint(1, len(X_test))\n",
    "plt.imshow(X_test[i])\n",
    "print('label = ', y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- Complete the code below to print out 5 by 5 grid showing random traffic sign images along with their corresponding labels as their titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-dc6a75caa1dc>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-dc6a75caa1dc>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Let's view more images in a grid format\n",
    "# Define the dimensions of the plot grid \n",
    "W_grid = 5\n",
    "L_grid = 5\n",
    "\n",
    "# fig, axes = plt.subplots(L_grid, W_grid)\n",
    "# subplot return the figure object and axes object\n",
    "# we can use the axes object to plot specific figures at various locations\n",
    "\n",
    "fig, axes = plt.subplots(L_grid, W_grid, figsize = (10,10))\n",
    "\n",
    "axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n",
    "\n",
    "n_training = len(X_test) # get the length of the training dataset\n",
    "\n",
    "# Select a random number from 0 to n_training\n",
    "for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #3: IMPORT SAGEMAKER/BOTO3, CREATE A SESSION, DEFINE S3 AND ROLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::542063182511:role/service-role/AmazonSageMaker-ExecutionRole-20191104T033920\n"
     ]
    }
   ],
   "source": [
    "# Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python\n",
    "# Boto3 allows Python developer to write software that makes use of services like Amazon S3 and Amazon EC2\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Let's create a Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Let's define the S3 bucket and prefix that we want to use in this session\n",
    "bucket = 'sagemaker-practical' # bucket named 'sagemaker-practical' was created beforehand\n",
    "prefix = 'traffic-sign-classifier' # prefix is the subfolder within the bucket.\n",
    "\n",
    "# Let's get the execution role for the notebook instance. \n",
    "# This is the IAM role that you created when you created your notebook instance. You pass the role to the training job.\n",
    "# Note that AWS Identity and Access Management (IAM) role that Amazon SageMaker can assume to perform tasks on your behalf (for example, reading training results, called model artifacts, from the S3 bucket and writing training results to Amazon S3). \n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #4: UPLOAD THE DATA TO S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to store the training and validation data\n",
    "\n",
    "import os\n",
    "os.makedirs(\"./data\", exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save several arrays into a single file in uncompressed .npz format\n",
    "# Read more here: https://numpy.org/devdocs/reference/generated/numpy.savez.html\n",
    "\n",
    "np.savez('./data/training', image = X_train, label = y_train)\n",
    "np.savez('./data/validation', image = X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-542063182511/traffic-sign/training/training.npz\n",
      "s3://sagemaker-us-east-2-542063182511/traffic-sign/validation/validation.npz\n"
     ]
    }
   ],
   "source": [
    "# Upload the training and validation data to S3 bucket\n",
    "\n",
    "prefix = 'traffic-sign'\n",
    "\n",
    "training_input_path   = sagemaker_session.upload_data('data/training.npz', key_prefix = prefix + '/training')\n",
    "validation_input_path = sagemaker_session.upload_data('data/validation.npz', key_prefix = prefix + '/validation')\n",
    "\n",
    "print(training_input_path)\n",
    "print(validation_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #5: TRAIN THE CNN LENET MODEL USING SAGEMAKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consists of the following layers: \n",
    "\n",
    "- STEP 1: THE FIRST CONVOLUTIONAL LAYER #1\n",
    "\n",
    "\n",
    "    - Input = 32x32x3\n",
    "    - Output = 28x28x6\n",
    "    - Output = (Input-filter+1)/Stride* => (32-5+1)/1=28\n",
    "    - Used a 5x5 Filter with input depth of 3 and output depth of 6\n",
    "    - Apply a RELU Activation function to the output\n",
    "    - pooling for input, Input = 28x28x6 and Output = 14x14x6\n",
    "\n",
    "\n",
    "    * Stride is the amount by which the kernel is shifted when the kernel is passed over the image.\n",
    "\n",
    "- STEP 2: THE SECOND CONVOLUTIONAL LAYER #2\n",
    "\n",
    "\n",
    "    - Input = 14x14x6\n",
    "    - Output = 10x10x16\n",
    "    - Layer 2: Convolutional layer with Output = 10x10x16\n",
    "    - Output = (Input-filter+1)/strides => 10 = 14-5+1/1\n",
    "    - Apply a RELU Activation function to the output\n",
    "    - Pooling with Input = 10x10x16 and Output = 5x5x16\n",
    "\n",
    "- STEP 3: FLATTENING THE NETWORK\n",
    "\n",
    "\n",
    "    - Flatten the network with Input = 5x5x16 and Output = 400\n",
    "\n",
    "- STEP 4: FULLY CONNECTED LAYER\n",
    "\n",
    "\n",
    "    - Layer 3: Fully Connected layer with Input = 400 and Output = 120\n",
    "    - Apply a RELU Activation function to the output\n",
    "\n",
    "- STEP 5: ANOTHER FULLY CONNECTED LAYER\n",
    "\n",
    "\n",
    "    - Layer 4: Fully Connected Layer with Input = 120 and Output = 84\n",
    "    - Apply a RELU Activation function to the output\n",
    "\n",
    "- STEP 6: FULLY CONNECTED LAYER\n",
    "\n",
    "\n",
    "    - Layer 5: Fully Connected layer with Input = 84 and Output = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m, \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m backend \u001b[34mas\u001b[39;49;00m K\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Sequential\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlayers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptimizers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Adam\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m multi_gpu_model\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# The training code will be contained in a main gaurd (if __name__ == '__main__') so SageMaker will execute the code found in the main. \u001b[39;49;00m\r\n",
      "\u001b[37m# argparse: \u001b[39;49;00m\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    \r\n",
      "    \u001b[37m# Parser to get the arguments\u001b[39;49;00m\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# Model hyperparameters are being sent as command-line arguments.\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--learning-rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.001\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m32\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m# The script receives environment variables in the training container instance. \u001b[39;49;00m\r\n",
      "    \u001b[37m# SM_NUM_GPUS: how many GPUs are available for trianing.\u001b[39;49;00m\r\n",
      "    \u001b[37m# SM_MODEL_DIR: A string indicating output path where model artifcats will be sent out to.\u001b[39;49;00m\r\n",
      "    \u001b[37m# SM_CHANNEL_TRAIN: path for the training channel \u001b[39;49;00m\r\n",
      "    \u001b[37m# SM_CHANNEL_VALIDATION: path for the validation channel\u001b[39;49;00m\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--gpu-count\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--training\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_VALIDATION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    args, _ = parser.parse_known_args()\r\n",
      "    \r\n",
      "    \u001b[37m# Hyperparameters\u001b[39;49;00m\r\n",
      "    epochs     = args.epochs\r\n",
      "    lr         = args.learning_rate\r\n",
      "    batch_size = args.batch_size\r\n",
      "    gpu_count  = args.gpu_count\r\n",
      "    model_dir  = args.model_dir\r\n",
      "    training_dir   = args.training\r\n",
      "    validation_dir = args.validation\r\n",
      "    \r\n",
      "    \u001b[37m# Loading the training and validation data from s3 bucket\u001b[39;49;00m\r\n",
      "    train_images = np.load(os.path.join(training_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtraining.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mimage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    train_labels = np.load(os.path.join(training_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtraining.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    test_images  = np.load(os.path.join(validation_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mimage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    test_labels  = np.load(os.path.join(validation_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation.npz\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))[\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\r\n",
      "    K.set_image_data_format(\u001b[33m'\u001b[39;49;00m\u001b[33mchannels_last\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Adding batch dimension to the input\u001b[39;49;00m\r\n",
      "    train_images = train_images.reshape(train_images.shape[\u001b[34m0\u001b[39;49;00m], \u001b[34m32\u001b[39;49;00m, \u001b[34m32\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m)\r\n",
      "    test_images = test_images.reshape(test_images.shape[\u001b[34m0\u001b[39;49;00m], \u001b[34m32\u001b[39;49;00m, \u001b[34m32\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m)\r\n",
      "    input_shape = (\u001b[34m32\u001b[39;49;00m, \u001b[34m32\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# Normalizing the data\u001b[39;49;00m\r\n",
      "    train_images = train_images.astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    test_images = test_images.astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    train_images /= \u001b[34m255\u001b[39;49;00m\r\n",
      "    test_images /= \u001b[34m255\u001b[39;49;00m\r\n",
      "\r\n",
      "    train_labels = tensorflow.keras.utils.to_categorical(train_labels, \u001b[34m43\u001b[39;49;00m)\r\n",
      "    test_labels = tensorflow.keras.utils.to_categorical(test_labels, \u001b[34m43\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#LeNet Network Architecture\u001b[39;49;00m\r\n",
      "    \r\n",
      "    model = Sequential()\r\n",
      "    \r\n",
      "    model.add(Conv2D(filters=\u001b[34m6\u001b[39;49;00m, kernel_size=(\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m), activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, input_shape= input_shape))\r\n",
      "    \r\n",
      "    model.add(AveragePooling2D())\r\n",
      "    \r\n",
      "    model.add(Conv2D(filters=\u001b[34m16\u001b[39;49;00m, kernel_size=(\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m), activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))   \r\n",
      "    \r\n",
      "    model.add(AveragePooling2D())\r\n",
      "    \r\n",
      "    model.add(Flatten())\r\n",
      "    \r\n",
      "    model.add(Dense(units=\u001b[34m120\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \r\n",
      "    model.add(Dense(units=\u001b[34m84\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \r\n",
      "    model.add(Dense(units=\u001b[34m43\u001b[39;49;00m, activation = \u001b[33m'\u001b[39;49;00m\u001b[33msoftmax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \r\n",
      "    \u001b[36mprint\u001b[39;49;00m(model.summary())\r\n",
      "\r\n",
      "    \r\n",
      "    \u001b[37m# If more than one GPU is available, convert the model to multi-gpu model\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m gpu_count > \u001b[34m1\u001b[39;49;00m:\r\n",
      "        \r\n",
      "        model = multi_gpu_model(model, gpus=gpu_count)\r\n",
      "\r\n",
      "    \u001b[37m# Compile and train the model\u001b[39;49;00m\r\n",
      "    model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\r\n",
      "                  optimizer=Adam(lr=lr),\r\n",
      "                  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    model.fit(train_images, train_labels, batch_size=batch_size,\r\n",
      "                  validation_data=(test_images, test_labels),\r\n",
      "                  epochs=epochs,\r\n",
      "                  verbose=\u001b[34m2\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Evaluating the model\u001b[39;49;00m\r\n",
      "    score = model.evaluate(test_images, test_labels, verbose=\u001b[34m0\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mValidation loss    :\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, score[\u001b[34m0\u001b[39;49;00m])\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mValidation accuracy:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, score[\u001b[34m1\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[37m# save trained CNN Keras model to \"model_dir\" (path specificied earlier)\u001b[39;49;00m\r\n",
      "    sess = K.get_session()\r\n",
      "    tensorflow.saved_model.simple_save(\r\n",
      "        sess,\r\n",
      "        os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel/1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\r\n",
      "        inputs={\u001b[33m'\u001b[39;49;00m\u001b[33minputs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: model.input},\r\n",
      "        outputs={t.name: t \u001b[34mfor\u001b[39;49;00m t \u001b[35min\u001b[39;49;00m model.outputs})\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train-cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# To Train a TensorFlow model, we will use TensorFlow estimator from the Sagemaker SDK\n",
    "\n",
    "# entry_point: a script that will run in a container. This script will include model description and training. \n",
    "# role: a role that's obtained The role assigned to the running notebook. \n",
    "# train_instance_count: number of container instances used to train the model.\n",
    "# train_instance_type: instance type!\n",
    "# framwork_version: version of Tensorflow\n",
    "# py_version: Python version.\n",
    "# script_mode: allows for running script in the container. \n",
    "# hyperparameters: indicate the hyperparameters for the training job such as epochs and learning rate\n",
    "\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='train-cnn.py', \n",
    "                          role=role,\n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='ml.c4.2xlarge',\n",
    "                          framework_version='1.12', \n",
    "                          py_version='py3',\n",
    "                          script_mode=True,\n",
    "                          hyperparameters={\n",
    "                              'epochs': 2 ,\n",
    "                              'batch-size': 32,\n",
    "                              'learning-rate': 0.001}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-25 19:08:12 Starting - Starting the training job...\n",
      "2021-03-25 19:08:35 Starting - Launching requested ML instancesProfilerReport-1616699291: InProgress\n",
      "......\n",
      "2021-03-25 19:09:35 Starting - Preparing the instances for training......\n",
      "2021-03-25 19:10:36 Downloading - Downloading input data\n",
      "2021-03-25 19:10:36 Training - Downloading the training image...\n",
      "2021-03-25 19:10:56 Training - Training image download completed. Training in progress.\u001b[34m2021-03-25 19:10:55,481 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-03-25 19:10:55,486 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-25 19:10:55,984 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-25 19:10:55,999 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-03-25 19:10:56,010 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 32,\n",
      "        \"learning-rate\": 0.001,\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/model\",\n",
      "        \"epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train-cnn\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-cnn.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":32,\"epochs\":2,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-cnn.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-cnn\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":32,\"epochs\":2,\"learning-rate\":0.001,\"model_dir\":\"s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/source/sourcedir.tar.gz\",\"module_name\":\"train-cnn\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-cnn.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"32\",\"--epochs\",\"2\",\"--learning-rate\",\"0.001\",\"--model_dir\",\"s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python train-cnn.py --batch-size 32 --epochs 2 --learning-rate 0.001 --model_dir s3://sagemaker-us-east-2-542063182511/sagemaker-tensorflow-scriptmode-2021-03-25-19-08-11-718/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mconv2d (Conv2D)              (None, 28, 28, 6)         456       \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34maverage_pooling2d (AveragePo (None, 14, 14, 6)         0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mconv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34maverage_pooling2d_1 (Average (None, 5, 5, 16)          0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mflatten (Flatten)            (None, 400)               0         \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense (Dense)                (None, 120)               48120     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_1 (Dense)              (None, 84)                10164     \u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mdense_2 (Dense)              (None, 43)                3655      \u001b[0m\n",
      "\u001b[34m=================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 64,811\u001b[0m\n",
      "\u001b[34mTrainable params: 64,811\u001b[0m\n",
      "\u001b[34mNon-trainable params: 0\u001b[0m\n",
      "\u001b[34m_________________________________________________________________\u001b[0m\n",
      "\u001b[34mNone\u001b[0m\n",
      "\u001b[34mTrain on 34799 samples, validate on 12630 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m - 16s - loss: 1.3469 - acc: 0.6285 - val_loss: 0.8516 - val_acc: 0.7862\u001b[0m\n",
      "\u001b[34mEpoch 2/2\u001b[0m\n",
      "\u001b[34m - 12s - loss: 0.3538 - acc: 0.9001 - val_loss: 0.6312 - val_acc: 0.8583\u001b[0m\n",
      "\u001b[34mValidation loss    : 0.6312200136063879\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.858273950919969\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/simple_save.py:85: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[34m2021-03-25 19:11:27,493 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-03-25 19:11:36 Uploading - Uploading generated training model\n",
      "2021-03-25 19:11:36 Completed - Training job completed\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n"
     ]
    }
   ],
   "source": [
    "tf_estimator.fit({'training': training_input_path, 'validation': validation_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #7: DEPLOY THE MODEL WITHOUT ACCELERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------"
     ]
    }
   ],
   "source": [
    "# Deploying the model\n",
    "\n",
    "import time\n",
    "\n",
    "tf_endpoint_name = 'trafficsignclassifier-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "tf_predictor = tf_estimator.deploy(initial_instance_count = 1,\n",
    "                         instance_type = 'ml.t2.medium',  \n",
    "                         endpoint_name = tf_endpoint_name)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions from the end point\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pre-processing the images\n",
    "\n",
    "num_samples = 5\n",
    "indices = random.sample(range(X_test.shape[0] - 1), num_samples)\n",
    "images = X_test[indices]/255\n",
    "labels = y_test[indices]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "# Making predictions \n",
    "\n",
    "prediction = tf_predictor.predict(images.reshape(num_samples, 32, 32, 3))['predictions']\n",
    "prediction = np.array(prediction)\n",
    "predicted_label = prediction.argmax(axis=1)\n",
    "print('Predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the end-point\n",
    "tf_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE (TAKE HOME)\n",
    " - Try to improve the model accuracy by experimenting with Dropout, adding more convolutional layers, and changing the size of the filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCELLENT JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE SOLUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Select a random number\n",
    "    index = np.random.randint(0, n_training)\n",
    "    # read and display an image with the selected index    \n",
    "    axes[i].imshow( X_test[index])\n",
    "    axes[i].set_title(y_test[index], fontsize = 15)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
